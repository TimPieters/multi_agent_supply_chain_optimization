{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /home/timpi/Projects/thesis/multi_agent_supply_chain_optimization\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set current working directory\n",
    "# Get the directory of the current notebook\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "# Set the working directory to the project root (one level up from the notebook directory)\n",
    "project_root = os.path.join(notebook_dir, os.pardir)\n",
    "os.chdir(project_root)\n",
    "\n",
    "# You can verify the new working directory\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")\n",
    "\n",
    "from notebooks.analysis.common_analysis_functions import get_baseline_objective, read_baseline_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration for CFLP --- \n",
    "CFLP_MODEL_FILE_PATH = 'models/CFLP/capfacloc_model.py'\n",
    "CFLP_DATA_CONFIGS = [\n",
    "    'models/CFLP/data/capfacloc_data_5cust_5fac.json',\n",
    "    'models/CFLP/data/capfacloc_data_10cust_10fac.json',\n",
    "    'models/CFLP/data/capfacloc_data_25cust_25fac.json',\n",
    "    'models/CFLP/data/capfacloc_data_50cust_50fac.json',\n",
    "    'models/CFLP/data/capfacloc_data_75cust_75fac.json',\n",
    "    'models/CFLP/data/capfacloc_data_100cust_100fac.json',\n",
    "    'models/CFLP/data/capfacloc_data_150cust_150fac.json',\n",
    "    'models/CFLP/data/capfacloc_data_200cust_200fac.json',       \n",
    "]\n",
    "\n",
    "# --- Configuration for VRP --- \n",
    "VRP_MODEL_FILE_PATH = 'models/VRP/vrp_model.py'\n",
    "VRP_DATA_CONFIGS = [\n",
    "    'models/VRP/data/vrp_data_5cust_1veh_50cap.json',\n",
    "    'models/VRP/data/vrp_data_5cust_2veh_50cap.json',\n",
    "    'models/VRP/data/vrp_data_10cust_1veh_50cap.json',\n",
    "    'models/VRP/data/vrp_data_10cust_1veh_100cap.json',\n",
    "    'models/VRP/data/vrp_data_10cust_2veh_50cap.json',\n",
    "    'models/VRP/data/vrp_data_10cust_2veh_100cap.json',\n",
    "    'models/VRP/data/vrp_data_10cust_5veh_50cap.json',\n",
    "    'models/VRP/data/vrp_data_15cust_1veh_100cap.json',\n",
    "]\n",
    "# Removed 'models/VRP/data/vrp_data_15cust_2veh_50cap.json' due to too long solve time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data as a list of dictionaries for easier plotting and labeling\n",
    "cflp_benchmark_data = []\n",
    "vrp_benchmark_data = []\n",
    "\n",
    "def generate_baselines(model_file_path, data_configs, model_type):\n",
    "    \"\"\"\n",
    "    Generates baseline logs for a given model type and its data configurations.\n",
    "    Collects execution times and parameter counts for plotting.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Generating Baselines for {model_type} ---\")\n",
    "    for data_path in data_configs:\n",
    "        current_execution_time = None\n",
    "        num_customers = 0\n",
    "        num_facilities_vehicles = 0\n",
    "        param_count = 0\n",
    "        size_str = 'default'\n",
    "\n",
    "        if model_type == 'CFLP':\n",
    "            data_config_match = re.search(r'capfacloc_data_([\\w_]+)\\.json', data_path)\n",
    "            log_filename_prefix = 'baseline_cflp_log'\n",
    "            \n",
    "            size_str = data_config_match.group(1) if data_config_match else 'default'\n",
    "            size_match = re.search(r'(\\d+)cust', size_str)\n",
    "            \n",
    "            if size_match:\n",
    "                num_customers_facilities = int(size_match.group(1))\n",
    "                num_customers = num_customers_facilities # For consistency in naming\n",
    "                num_facilities_vehicles = num_customers_facilities # For consistency in naming\n",
    "                # Corrected parameter count: N demands + N fixed costs + N capacities + N*N transportation costs\n",
    "                param_count = num_customers_facilities + num_customers_facilities + num_customers_facilities + (num_customers_facilities * num_customers_facilities)\n",
    "            \n",
    "        elif model_type == 'VRP':\n",
    "            data_config_match = re.search(r'vrp_data_([\\w_]+)\\.json', data_path)\n",
    "            log_filename_prefix = 'baseline_vrp_log'\n",
    "            \n",
    "            size_str = data_config_match.group(1) if data_config_match else 'default'\n",
    "            cust_match = re.search(r'(\\d+)cust', size_str)\n",
    "            veh_match = re.search(r'(\\d+)veh', size_str)\n",
    "\n",
    "            if cust_match and veh_match:\n",
    "                num_customers = int(cust_match.group(1))\n",
    "                num_vehicles = int(veh_match.group(1))\n",
    "                num_facilities_vehicles = num_vehicles # For consistency in naming\n",
    "                # VRP parameter count: C (customers) + V (vehicles) + (C+1)^2 (distances) + C (demands) + V (capacities)\n",
    "                param_count = num_customers + num_vehicles + ((num_customers + 1)**2) + num_customers + num_vehicles\n",
    "                \n",
    "        else:\n",
    "            data_config_match = None\n",
    "            log_filename_prefix = 'baseline_log'\n",
    "\n",
    "        # Define the baseline log directory within the model's folder\n",
    "        baseline_log_dir = Path(model_file_path).parent / 'baselines'\n",
    "        baseline_log_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        baseline_log_filepath = baseline_log_dir / f'{log_filename_prefix}_{size_str}.csv'\n",
    "        \n",
    "        print(f\"Generating baseline for {data_path} -> {baseline_log_filepath}\")\n",
    "        # Call get_baseline_objective to ensure the CSV is generated\n",
    "        get_baseline_objective(model_file_path, data_path, str(baseline_log_filepath))\n",
    "        \n",
    "        # Read the generated CSV to get the execution time\n",
    "        df_log = read_baseline_log(str(baseline_log_filepath))\n",
    "        if not df_log.empty and 'pulp_model_execution_time' in df_log.columns:\n",
    "            # Assuming only one entry per baseline log for simplicity\n",
    "            current_execution_time = df_log['pulp_model_execution_time'].iloc[0]\n",
    "        \n",
    "        if model_type == 'CFLP':\n",
    "            cflp_benchmark_data.append({\n",
    "                'size': num_customers, # Using num_customers as the primary size metric\n",
    "                'execution_time': current_execution_time,\n",
    "                'parameter_count': param_count,\n",
    "                'config_str': size_str\n",
    "            })\n",
    "        elif model_type == 'VRP':\n",
    "            vrp_benchmark_data.append({\n",
    "                'size': num_customers, # Using num_customers as the primary size metric\n",
    "                'execution_time': current_execution_time,\n",
    "                'parameter_count': param_count,\n",
    "                'config_str': size_str\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Baselines for CFLP ---\n",
      "Generating baseline for models/CFLP/data/capfacloc_data_5cust_5fac.json -> models/CFLP/baselines/baseline_cflp_log_5cust_5fac.csv\n",
      "Running baseline model from models/CFLP/capfacloc_model.py with data models/CFLP/data/capfacloc_data_5cust_5fac.json...\n",
      "Baseline objective value: 223.0\n",
      "Baseline log file loaded from models/CFLP/baselines/baseline_cflp_log_5cust_5fac.csv.\n",
      "Generating baseline for models/CFLP/data/capfacloc_data_10cust_10fac.json -> models/CFLP/baselines/baseline_cflp_log_10cust_10fac.csv\n",
      "Running baseline model from models/CFLP/capfacloc_model.py with data models/CFLP/data/capfacloc_data_10cust_10fac.json...\n",
      "Baseline objective value: 436.0625\n",
      "Baseline log file loaded from models/CFLP/baselines/baseline_cflp_log_10cust_10fac.csv.\n",
      "Generating baseline for models/CFLP/data/capfacloc_data_25cust_25fac.json -> models/CFLP/baselines/baseline_cflp_log_25cust_25fac.csv\n",
      "Running baseline model from models/CFLP/capfacloc_model.py with data models/CFLP/data/capfacloc_data_25cust_25fac.json...\n",
      "Baseline objective value: 1093.601814554\n",
      "Baseline log file loaded from models/CFLP/baselines/baseline_cflp_log_25cust_25fac.csv.\n",
      "Generating baseline for models/CFLP/data/capfacloc_data_50cust_50fac.json -> models/CFLP/baselines/baseline_cflp_log_50cust_50fac.csv\n",
      "Running baseline model from models/CFLP/capfacloc_model.py with data models/CFLP/data/capfacloc_data_50cust_50fac.json...\n",
      "Baseline objective value: 1919.00000004\n",
      "Baseline log file loaded from models/CFLP/baselines/baseline_cflp_log_50cust_50fac.csv.\n",
      "Generating baseline for models/CFLP/data/capfacloc_data_75cust_75fac.json -> models/CFLP/baselines/baseline_cflp_log_75cust_75fac.csv\n",
      "Running baseline model from models/CFLP/capfacloc_model.py with data models/CFLP/data/capfacloc_data_75cust_75fac.json...\n",
      "Baseline objective value: 2925.628183577\n",
      "Baseline log file loaded from models/CFLP/baselines/baseline_cflp_log_75cust_75fac.csv.\n",
      "Generating baseline for models/CFLP/data/capfacloc_data_100cust_100fac.json -> models/CFLP/baselines/baseline_cflp_log_100cust_100fac.csv\n",
      "Running baseline model from models/CFLP/capfacloc_model.py with data models/CFLP/data/capfacloc_data_100cust_100fac.json...\n",
      "Baseline objective value: 3812.5714286600005\n",
      "Baseline log file loaded from models/CFLP/baselines/baseline_cflp_log_100cust_100fac.csv.\n",
      "Generating baseline for models/CFLP/data/capfacloc_data_150cust_150fac.json -> models/CFLP/baselines/baseline_cflp_log_150cust_150fac.csv\n",
      "Running baseline model from models/CFLP/capfacloc_model.py with data models/CFLP/data/capfacloc_data_150cust_150fac.json...\n",
      "Baseline objective value: 5789.0\n",
      "Baseline log file loaded from models/CFLP/baselines/baseline_cflp_log_150cust_150fac.csv.\n",
      "Generating baseline for models/CFLP/data/capfacloc_data_200cust_200fac.json -> models/CFLP/baselines/baseline_cflp_log_200cust_200fac.csv\n",
      "Running baseline model from models/CFLP/capfacloc_model.py with data models/CFLP/data/capfacloc_data_200cust_200fac.json...\n",
      "Baseline objective value: 7889.000000110001\n",
      "Baseline log file loaded from models/CFLP/baselines/baseline_cflp_log_200cust_200fac.csv.\n"
     ]
    }
   ],
   "source": [
    "# Run for CFLP\n",
    "generate_baselines(CFLP_MODEL_FILE_PATH, CFLP_DATA_CONFIGS, 'CFLP')\n",
    "\n",
    "# Convert collected data to DataFrame for easier plotting\n",
    "df_cflp_benchmark = pd.DataFrame(cflp_benchmark_data)\n",
    "df_cflp_benchmark = df_cflp_benchmark.dropna(subset=['execution_time', 'parameter_count']) # Remove rows with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Baselines for VRP ---\n",
      "Generating baseline for models/VRP/data/vrp_data_5cust_1veh_50cap.json -> models/VRP/baselines/baseline_vrp_log_5cust_1veh_50cap.csv\n",
      "Running baseline model from models/VRP/vrp_model.py with data models/VRP/data/vrp_data_5cust_1veh_50cap.json...\n",
      "Baseline objective value: 241.07\n",
      "Baseline log file loaded from models/VRP/baselines/baseline_vrp_log_5cust_1veh_50cap.csv.\n",
      "Generating baseline for models/VRP/data/vrp_data_5cust_2veh_50cap.json -> models/VRP/baselines/baseline_vrp_log_5cust_2veh_50cap.csv\n",
      "Running baseline model from models/VRP/vrp_model.py with data models/VRP/data/vrp_data_5cust_2veh_50cap.json...\n",
      "Baseline objective value: 241.07\n",
      "Baseline log file loaded from models/VRP/baselines/baseline_vrp_log_5cust_2veh_50cap.csv.\n",
      "Generating baseline for models/VRP/data/vrp_data_10cust_1veh_50cap.json -> models/VRP/baselines/baseline_vrp_log_10cust_1veh_50cap.csv\n",
      "Running baseline model from models/VRP/vrp_model.py with data models/VRP/data/vrp_data_10cust_1veh_50cap.json...\n",
      "Failed to get optimal baseline objective: {'status': 'Infeasible', 'raw_status': -1, 'solution': {}, 'total_cost': None, 'message': 'The model is infeasible. The constraints are conflicting.'}\n",
      "Baseline log file loaded from models/VRP/baselines/baseline_vrp_log_10cust_1veh_50cap.csv.\n",
      "Generating baseline for models/VRP/data/vrp_data_10cust_1veh_100cap.json -> models/VRP/baselines/baseline_vrp_log_10cust_1veh_100cap.csv\n",
      "Running baseline model from models/VRP/vrp_model.py with data models/VRP/data/vrp_data_10cust_1veh_100cap.json...\n",
      "Baseline objective value: 296.26000000000005\n",
      "Baseline log file loaded from models/VRP/baselines/baseline_vrp_log_10cust_1veh_100cap.csv.\n",
      "Generating baseline for models/VRP/data/vrp_data_10cust_2veh_50cap.json -> models/VRP/baselines/baseline_vrp_log_10cust_2veh_50cap.csv\n",
      "Running baseline model from models/VRP/vrp_model.py with data models/VRP/data/vrp_data_10cust_2veh_50cap.json...\n",
      "Baseline objective value: 330.1\n",
      "Baseline log file loaded from models/VRP/baselines/baseline_vrp_log_10cust_2veh_50cap.csv.\n",
      "Generating baseline for models/VRP/data/vrp_data_10cust_2veh_100cap.json -> models/VRP/baselines/baseline_vrp_log_10cust_2veh_100cap.csv\n",
      "Running baseline model from models/VRP/vrp_model.py with data models/VRP/data/vrp_data_10cust_2veh_100cap.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Execution Error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/timpi/Projects/thesis/multi_agent_supply_chain_optimization/utils.py\", line 94, in _run_with_exec\n",
      "    exec(src_code, locals_dict, locals_dict)\n",
      "  File \"<string>\", line 21, in <module>\n",
      "KeyError: 'coords'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline objective value: 296.26000000000005\n",
      "Baseline log file loaded from models/VRP/baselines/baseline_vrp_log_10cust_2veh_100cap.csv.\n",
      "Generating baseline for models/VRP/data/vrp_data_10cust_5veh_50cap.json -> models/VRP/baselines/baseline_vrp_log_10cust_5veh_50cap.csv\n",
      "Running baseline model from models/VRP/vrp_model.py with data models/VRP/data/vrp_data_10cust_5veh_50cap.json...\n",
      "Failed to get optimal baseline objective: {'status': 'Error', 'message': \"Model execution failed or 'model' not found in locals_dict.\"}\n",
      "Baseline log file not found at models/VRP/baselines/baseline_vrp_log_10cust_5veh_50cap.csv. Please run baseline model first.\n",
      "Generating baseline for models/VRP/data/vrp_data_15cust_1veh_100cap.json -> models/VRP/baselines/baseline_vrp_log_15cust_1veh_100cap.csv\n",
      "Running baseline model from models/VRP/vrp_model.py with data models/VRP/data/vrp_data_15cust_1veh_100cap.json...\n",
      "Baseline objective value: 321.65999999999997\n",
      "Baseline log file loaded from models/VRP/baselines/baseline_vrp_log_15cust_1veh_100cap.csv.\n"
     ]
    }
   ],
   "source": [
    "# Run for VRP\n",
    "generate_baselines(VRP_MODEL_FILE_PATH, VRP_DATA_CONFIGS, 'VRP')\n",
    "\n",
    "df_vrp_benchmark = pd.DataFrame(vrp_benchmark_data)\n",
    "df_vrp_benchmark = df_vrp_benchmark.dropna(subset=['execution_time', 'parameter_count']) # Remove rows with missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CFLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Plotting CFLP Execution Times ---\n",
      "Plot saved to: results/baseline_analysis_plots/cflp_execution_time_vs_data_size.png\n",
      "\n",
      "--- Plotting CFLP Parameter Counts ---\n",
      "Parameter count plot saved to: results/baseline_analysis_plots/cflp_parameter_count_vs_data_size.png\n",
      "\n",
      "--- Plotting Overlay of Execution Time and Parameter Count (CFLP) ---\n",
      "Overlay plot saved to: results/baseline_analysis_plots/cflp_execution_time_and_parameter_count_overlay.png\n"
     ]
    }
   ],
   "source": [
    "# --- Plotting CFLP Execution Times ---\n",
    "print(\"\\n--- Plotting CFLP Execution Times ---\")\n",
    "if not df_cflp_benchmark.empty:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot the line connecting all points\n",
    "    plt.plot(df_cflp_benchmark['size'], df_cflp_benchmark['execution_time'], color='blue', linestyle='-')\n",
    "\n",
    "    # Plot each point as a scatter plot with its label for the legend\n",
    "    scatter_handles = []\n",
    "    for i, row in df_cflp_benchmark.iterrows():\n",
    "        scatter_handle = plt.scatter(row['size'], row['execution_time'], marker='o', label=row['config_str'], color='blue')\n",
    "        scatter_handles.append(scatter_handle)\n",
    "\n",
    "    plt.title('CFLP Model Execution Time vs. Data Size')\n",
    "    plt.xlabel('Number of Customers/Facilities (N)')\n",
    "    plt.ylabel('PULP Model Execution Time (seconds)')\n",
    "    plt.grid(True)\n",
    "    plt.legend(handles=scatter_handles, title='Data Configuration', bbox_to_anchor=(1.05, 1), loc='upper left') # Place legend outside\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_output_dir = Path('results/baseline_analysis_plots')\n",
    "    plot_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    plot_path = plot_output_dir / 'cflp_execution_time_vs_data_size.png'\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    print(f\"Plot saved to: {plot_path}\")\n",
    "else:\n",
    "    print(\"No valid CFLP execution time data to plot.\")\n",
    "\n",
    "# --- Plotting CFLP Parameter Counts ---\n",
    "print(\"\\n--- Plotting CFLP Parameter Counts ---\")\n",
    "if not df_cflp_benchmark.empty:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot the line connecting all points\n",
    "    plt.plot(df_cflp_benchmark['size'], df_cflp_benchmark['parameter_count'], color='blue', linestyle='-')\n",
    "\n",
    "    # Plot each point as a scatter plot with its label for the legend\n",
    "    scatter_handles = []\n",
    "    for i, row in df_cflp_benchmark.iterrows():\n",
    "        scatter_handle = plt.scatter(row['size'], row['parameter_count'], marker='o', label=row['config_str'], color='blue')\n",
    "        scatter_handles.append(scatter_handle)\n",
    "\n",
    "    plt.title('CFLP Model Parameter Count vs. Data Size')\n",
    "    plt.xlabel('Number of Customers/Facilities (N)')\n",
    "    plt.ylabel('Total Parameter Count (3N + N^2)')\n",
    "    plt.grid(True)\n",
    "    plt.legend(handles=scatter_handles, title='Data Configuration', bbox_to_anchor=(1.05, 1), loc='upper left') # Place legend outside\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_output_dir = Path('results/baseline_analysis_plots')\n",
    "    plot_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    plot_path_params = plot_output_dir / 'cflp_parameter_count_vs_data_size.png'\n",
    "    plt.savefig(plot_path_params)\n",
    "    plt.close()\n",
    "    print(f\"Parameter count plot saved to: {plot_path_params}\")\n",
    "else:\n",
    "    print(\"No valid CFLP parameter count data to plot.\")\n",
    "\n",
    "# --- Overlay Plot: Execution Time and Parameter Count (CFLP) ---\n",
    "print(\"\\n--- Plotting Overlay of Execution Time and Parameter Count (CFLP) ---\")\n",
    "if not df_cflp_benchmark.empty:\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot Execution Time\n",
    "    sns.lineplot(data=df_cflp_benchmark, x='size', y='execution_time', marker='o', ax=ax1, color='blue', label='Execution Time')\n",
    "    ax1.set_xlabel('Number of Customers/Facilities (N)')\n",
    "    ax1.set_ylabel('PULP Model Execution Time (seconds)', color='blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='blue')\n",
    "    ax1.grid(True, which=\"both\", ls=\"-\", alpha=0.7)\n",
    "\n",
    "    # Create a second y-axis for Parameter Count\n",
    "    ax2 = ax1.twinx()\n",
    "    sns.lineplot(data=df_cflp_benchmark, x='size', y='parameter_count', marker='x', ax=ax2, color='red', label='Parameter Count')\n",
    "    ax2.set_ylabel('Total Parameter Count (3N + N^2)', color='red')\n",
    "    ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "    # Combine legends\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "\n",
    "    plt.title('CFLP Model Performance: Execution Time & Parameter Count vs. Data Size')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_output_dir = Path('results/baseline_analysis_plots')\n",
    "    plot_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    plot_path_combined = plot_output_dir / 'cflp_execution_time_and_parameter_count_overlay.png'\n",
    "    plt.savefig(plot_path_combined)\n",
    "    plt.close()\n",
    "    print(f\"Overlay plot saved to: {plot_path_combined}\")\n",
    "else:\n",
    "    print(\"Not enough CFLP data collected for overlay plotting.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Plotting VRP Execution Times ---\n",
      "Plot saved to: results/baseline_analysis_plots/vrp_execution_time_vs_data_size.png\n",
      "\n",
      "--- Plotting VRP Parameter Counts ---\n",
      "Parameter count plot saved to: results/baseline_analysis_plots/vrp_parameter_count_vs_data_size.png\n",
      "\n",
      "--- Plotting Overlay of Execution Time and Parameter Count (VRP) ---\n",
      "Overlay plot saved to: results/baseline_analysis_plots/vrp_execution_time_and_parameter_count_overlay.png\n"
     ]
    }
   ],
   "source": [
    "# --- Plotting VRP Execution Times ---\n",
    "print(\"\\n--- Plotting VRP Execution Times ---\")\n",
    "if not df_vrp_benchmark.empty:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot the line connecting all points\n",
    "    plt.plot(df_vrp_benchmark['size'], df_vrp_benchmark['execution_time'], color='blue', linestyle='-')\n",
    "\n",
    "    # Plot each point as a scatter plot with its label for the legend\n",
    "    scatter_handles_vrp = []\n",
    "    for i, row in df_vrp_benchmark.iterrows():\n",
    "        scatter_handle_vrp = plt.scatter(row['size'], row['execution_time'], marker='o', label=row['config_str'], color='blue')\n",
    "        scatter_handles_vrp.append(scatter_handle_vrp)\n",
    "\n",
    "    plt.title('VRP Model Execution Time vs. Number of Customers')\n",
    "    plt.xlabel('Number of Customers (C)')\n",
    "    plt.ylabel('PULP Model Execution Time (seconds)')\n",
    "    plt.grid(True)\n",
    "    plt.xscale('log') # Re-adding log scale for x-axis\n",
    "    plt.xticks(df_vrp_benchmark['size'], [str(s) for s in df_vrp_benchmark['size']]) # Ensure all sizes are shown as ticks\n",
    "    plt.legend(handles=scatter_handles_vrp, title='Data Configuration', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_output_dir = Path('results/baseline_analysis_plots')\n",
    "    plot_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    plot_path = plot_output_dir / 'vrp_execution_time_vs_data_size.png'\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    print(f\"Plot saved to: {plot_path}\")\n",
    "else:\n",
    "    print(\"No valid VRP execution time data to plot.\")\n",
    "\n",
    "# --- Plotting VRP Parameter Counts ---\n",
    "print(\"\\n--- Plotting VRP Parameter Counts ---\")\n",
    "if not df_vrp_benchmark.empty:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot the line connecting all points\n",
    "    plt.plot(df_vrp_benchmark['size'], df_vrp_benchmark['parameter_count'], color='blue', linestyle='-')\n",
    "\n",
    "    # Plot each point as a scatter plot with its label for the legend\n",
    "    scatter_handles_vrp_params = []\n",
    "    for i, row in df_vrp_benchmark.iterrows():\n",
    "        scatter_handle_vrp_params = plt.scatter(row['size'], row['parameter_count'], marker='o', label=row['config_str'], color='blue')\n",
    "        scatter_handles_vrp_params.append(scatter_handle_vrp_params)\n",
    "\n",
    "    plt.title('VRP Model Parameter Count vs. Number of Customers')\n",
    "    plt.xlabel('Number of Customers (C)')\n",
    "    plt.ylabel('Total Parameter Count (2C + 2V + (C+1)^2)')\n",
    "    plt.grid(True)\n",
    "    plt.xscale('log') # Re-adding log scale for x-axis\n",
    "    plt.xticks(df_vrp_benchmark['size'], [str(s) for s in df_vrp_benchmark['size']]) # Ensure all sizes are shown as ticks\n",
    "    plt.legend(handles=scatter_handles_vrp_params, title='Data Configuration', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_output_dir = Path('results/baseline_analysis_plots')\n",
    "    plot_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    plot_path_params = plot_output_dir / 'vrp_parameter_count_vs_data_size.png'\n",
    "    plt.savefig(plot_path_params)\n",
    "    plt.close()\n",
    "    print(f\"Parameter count plot saved to: {plot_path_params}\")\n",
    "else:\n",
    "    print(\"No valid VRP parameter count data to plot.\")\n",
    "\n",
    "# --- Overlay Plot: Execution Time and Parameter Count (VRP) ---\n",
    "print(\"\\n--- Plotting Overlay of Execution Time and Parameter Count (VRP) ---\")\n",
    "if not df_vrp_benchmark.empty:\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot Execution Time\n",
    "    sns.lineplot(data=df_vrp_benchmark, x='size', y='execution_time', marker='o', ax=ax1, color='blue', label='Execution Time')\n",
    "    ax1.set_xlabel('Number of Customers (C)')\n",
    "    ax1.set_ylabel('PULP Model Execution Time (seconds)', color='blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='blue')\n",
    "    ax1.grid(True, which=\"both\", ls=\"-\", alpha=0.7)\n",
    "    ax1.set_xscale('log') # Re-adding log scale for x-axis\n",
    "    ax1.set_xticks(df_vrp_benchmark['size'])\n",
    "    ax1.set_xticklabels([str(s) for s in df_vrp_benchmark['size']])\n",
    "\n",
    "    # Create a second y-axis for Parameter Count\n",
    "    ax2 = ax1.twinx()\n",
    "    sns.lineplot(data=df_vrp_benchmark, x='size', y='parameter_count', marker='x', ax=ax2, color='red', label='Parameter Count')\n",
    "    ax2.set_ylabel('Total Parameter Count (2C + 2V + (C+1)^2)', color='red')\n",
    "    ax2.tick_params(axis='y', labelcolor='red')\n",
    "    ax2.set_yscale('log') # Re-adding log scale for y-axis for parameter count in overlay\n",
    "\n",
    "    # Combine legends\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "\n",
    "    plt.title('VRP Model Performance: Execution Time & Parameter Count vs. Data Size')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_output_dir = Path('results/baseline_analysis_plots')\n",
    "    plot_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    plot_path_combined = plot_output_dir / 'vrp_execution_time_and_parameter_count_overlay.png'\n",
    "    plt.savefig(plot_path_combined)\n",
    "    plt.close()\n",
    "    print(f\"Overlay plot saved to: {plot_path_combined}\")\n",
    "else:\n",
    "    print(\"Not enough VRP data collected for overlay plotting.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
