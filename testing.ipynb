{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b96db28",
   "metadata": {},
   "source": [
    "# This is a notebook for some testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f6f3643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\timpi\\\\Documents\\\\Ugent\\\\Masterproef\\\\multi_agent_supply_chain_optimization\\\\capfacloc_model.py', 'c:\\\\Users\\\\timpi\\\\Documents\\\\Ugent\\\\Masterproef\\\\multi_agent_supply_chain_optimization\\\\coder_agent.py', 'c:\\\\Users\\\\timpi\\\\Documents\\\\Ugent\\\\Masterproef\\\\multi_agent_supply_chain_optimization\\\\contrast_extract_mps_info.py', 'c:\\\\Users\\\\timpi\\\\Documents\\\\Ugent\\\\Masterproef\\\\multi_agent_supply_chain_optimization\\\\main.py', 'c:\\\\Users\\\\timpi\\\\Documents\\\\Ugent\\\\Masterproef\\\\multi_agent_supply_chain_optimization\\\\run.py', 'c:\\\\Users\\\\timpi\\\\Documents\\\\Ugent\\\\Masterproef\\\\multi_agent_supply_chain_optimization\\\\scenario_planner.py', 'c:\\\\Users\\\\timpi\\\\Documents\\\\Ugent\\\\Masterproef\\\\multi_agent_supply_chain_optimization\\\\sensitivity_analysis.py', 'c:\\\\Users\\\\timpi\\\\Documents\\\\Ugent\\\\Masterproef\\\\multi_agent_supply_chain_optimization\\\\simple_model.py', 'c:\\\\Users\\\\timpi\\\\Documents\\\\Ugent\\\\Masterproef\\\\multi_agent_supply_chain_optimization\\\\traditional_sensitivity_analysis.py', 'c:\\\\Users\\\\timpi\\\\Documents\\\\Ugent\\\\Masterproef\\\\multi_agent_supply_chain_optimization\\\\utils.py', 'c:\\\\Users\\\\timpi\\\\Documents\\\\Ugent\\\\Masterproef\\\\multi_agent_supply_chain_optimization\\\\generator_classes\\\\capfacloc.py', 'c:\\\\Users\\\\timpi\\\\Documents\\\\Ugent\\\\Masterproef\\\\multi_agent_supply_chain_optimization\\\\MILP_models\\\\capfac.py', 'c:\\\\Users\\\\timpi\\\\Documents\\\\Ugent\\\\Masterproef\\\\multi_agent_supply_chain_optimization\\\\scenario\\\\scenario_grading.py']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import importlib.util\n",
    "\n",
    "# Get the current working directory\n",
    "project_dir = os.getcwd()\n",
    "\n",
    "# List all Python files in the project directory\n",
    "python_files = glob.glob(os.path.join(project_dir, '**', '*.py'), recursive=True)\n",
    "\n",
    "print(python_files)\n",
    "\n",
    "# import the python_files as modules\n",
    "for file in python_files:\n",
    "    module_name = os.path.splitext(os.path.basename(file))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00c29131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contrast_extract_mps_info import analyze_mps, analyze_mps_high_level\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95888e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objective_function</th>\n",
       "      <th>constraints</th>\n",
       "      <th>rhs_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>TotalCost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coefficients</th>\n",
       "      <td>{'Open_0': 150.0, 'Open_1': 180.0, 'Open_2': 1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demand_0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'G', 'coefficients': {'Serve_0_0': 1....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demand_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'G', 'coefficients': {'Serve_1_0': 1....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demand_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'G', 'coefficients': {'Serve_2_0': 1....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demand_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'G', 'coefficients': {'Serve_3_0': 1....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demand_4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'G', 'coefficients': {'Serve_4_0': 1....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Capacity_0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'L', 'coefficients': {'Open_0': -80.0...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Capacity_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'L', 'coefficients': {'Open_1': -90.0...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Capacity_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'L', 'coefficients': {'Open_2': -70.0...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Capacity_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'L', 'coefficients': {'Open_3': -100....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Capacity_4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'L', 'coefficients': {'Open_4': -85.0...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalDemand</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'G', 'coefficients': {'Open_0': 80.0,...</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Link_0_0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'L', 'coefficients': {'Open_0': -1.0,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Link_0_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'L', 'coefficients': {'Open_1': -1.0,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Link_0_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'L', 'coefficients': {'Open_2': -1.0,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Link_0_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'L', 'coefficients': {'Open_3': -1.0,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Link_0_4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'L', 'coefficients': {'Open_4': -1.0,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Link_1_0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'L', 'coefficients': {'Open_0': -1.0,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Link_1_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'L', 'coefficients': {'Open_1': -1.0,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             objective_function  \\\n",
       "name                                                  TotalCost   \n",
       "coefficients  {'Open_0': 150.0, 'Open_1': 180.0, 'Open_2': 1...   \n",
       "Demand_0                                                    NaN   \n",
       "Demand_1                                                    NaN   \n",
       "Demand_2                                                    NaN   \n",
       "Demand_3                                                    NaN   \n",
       "Demand_4                                                    NaN   \n",
       "Capacity_0                                                  NaN   \n",
       "Capacity_1                                                  NaN   \n",
       "Capacity_2                                                  NaN   \n",
       "Capacity_3                                                  NaN   \n",
       "Capacity_4                                                  NaN   \n",
       "TotalDemand                                                 NaN   \n",
       "Link_0_0                                                    NaN   \n",
       "Link_0_1                                                    NaN   \n",
       "Link_0_2                                                    NaN   \n",
       "Link_0_3                                                    NaN   \n",
       "Link_0_4                                                    NaN   \n",
       "Link_1_0                                                    NaN   \n",
       "Link_1_1                                                    NaN   \n",
       "\n",
       "                                                    constraints rhs_values  \n",
       "name                                                        NaN        NaN  \n",
       "coefficients                                                NaN        NaN  \n",
       "Demand_0      {'type': 'G', 'coefficients': {'Serve_0_0': 1....        1.0  \n",
       "Demand_1      {'type': 'G', 'coefficients': {'Serve_1_0': 1....        1.0  \n",
       "Demand_2      {'type': 'G', 'coefficients': {'Serve_2_0': 1....        1.0  \n",
       "Demand_3      {'type': 'G', 'coefficients': {'Serve_3_0': 1....        1.0  \n",
       "Demand_4      {'type': 'G', 'coefficients': {'Serve_4_0': 1....        1.0  \n",
       "Capacity_0    {'type': 'L', 'coefficients': {'Open_0': -80.0...        0.0  \n",
       "Capacity_1    {'type': 'L', 'coefficients': {'Open_1': -90.0...        0.0  \n",
       "Capacity_2    {'type': 'L', 'coefficients': {'Open_2': -70.0...        0.0  \n",
       "Capacity_3    {'type': 'L', 'coefficients': {'Open_3': -100....        0.0  \n",
       "Capacity_4    {'type': 'L', 'coefficients': {'Open_4': -85.0...        0.0  \n",
       "TotalDemand   {'type': 'G', 'coefficients': {'Open_0': 80.0,...      115.0  \n",
       "Link_0_0      {'type': 'L', 'coefficients': {'Open_0': -1.0,...        0.0  \n",
       "Link_0_1      {'type': 'L', 'coefficients': {'Open_1': -1.0,...        0.0  \n",
       "Link_0_2      {'type': 'L', 'coefficients': {'Open_2': -1.0,...        0.0  \n",
       "Link_0_3      {'type': 'L', 'coefficients': {'Open_3': -1.0,...        0.0  \n",
       "Link_0_4      {'type': 'L', 'coefficients': {'Open_4': -1.0,...        0.0  \n",
       "Link_1_0      {'type': 'L', 'coefficients': {'Open_0': -1.0,...        0.0  \n",
       "Link_1_1      {'type': 'L', 'coefficients': {'Open_1': -1.0,...        0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage:\n",
    "file_path = os.path.join(project_dir, \"CapacitatedFacilityLocation.mps\")\n",
    "mps_data = analyze_mps(file_path)\n",
    "\n",
    "df = pd.DataFrame.from_dict(mps_data, orient='index')\n",
    "df = df.transpose()\n",
    "df.head(20)\n",
    "# print a subset of df\n",
    "#df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21ff21e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective_function': {'name': 'TotalCost', 'num_coefficients': 30},\n",
       " 'constraints': {'total': 36,\n",
       "  'types': {'equality': 0, 'less_than_equal': 30, 'greater_than_equal': 6}},\n",
       " 'rhs_values': {'total': 36,\n",
       "  'sample': [('Demand_0', 1.0),\n",
       "   ('Demand_1', 1.0),\n",
       "   ('Demand_2', 1.0),\n",
       "   ('Demand_3', 1.0),\n",
       "   ('Demand_4', 1.0)]}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_mps_high_level(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b04ef08",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_gzip' from 'utils' (c:\\Users\\timpi\\Documents\\Ugent\\Masterproef\\multi_agent_supply_chain_optimization\\utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_gzip, load_json\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mBipartiteNodeData\u001b[39;00m(torch_geometric.data.Data):\n\u001b[32m     12\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[33;03m    This class encode a node bipartite graph observation as returned by the ecole.observation.NodeBipartite\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03m    observation function in a format understood by the pytorch geometric data handlers.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'load_gzip' from 'utils' (c:\\Users\\timpi\\Documents\\Ugent\\Masterproef\\multi_agent_supply_chain_optimization\\utils.py)"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from utils import load_gzip, load_json\n",
    "\n",
    "\n",
    "class BipartiteNodeData(torch_geometric.data.Data):\n",
    "    \"\"\"\n",
    "    This class encode a node bipartite graph observation as returned by the ecole.observation.NodeBipartite\n",
    "    observation function in a format understood by the pytorch geometric data handlers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        constraint_features,\n",
    "        edge_indices,\n",
    "        edge_features,\n",
    "        variable_features,\n",
    "        candidates,\n",
    "        nb_candidates,\n",
    "        candidate_choice,\n",
    "        candidate_scores,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.constraint_features = constraint_features\n",
    "        self.edge_index = edge_indices\n",
    "        self.edge_attr = edge_features\n",
    "        self.variable_features = variable_features\n",
    "        self.candidates = candidates\n",
    "        self.nb_candidates = nb_candidates\n",
    "        self.candidate_choices = candidate_choice\n",
    "        self.candidate_scores = candidate_scores\n",
    "\n",
    "    def __inc__(self, key, value, store, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        We overload the pytorch geometric method that tells how to increment indices when concatenating graphs\n",
    "        for those entries (edge index, candidates) for which this is not obvious.\n",
    "        \"\"\"\n",
    "        if key == \"edge_index\":\n",
    "            return torch.tensor(\n",
    "                [[self.constraint_features.size(0)], [self.variable_features.size(0)]]\n",
    "            )\n",
    "        elif key == \"candidates\":\n",
    "            return self.variable_features.size(0)\n",
    "        else:\n",
    "            return super().__inc__(key, value, *args, **kwargs)\n",
    "\n",
    "\n",
    "class GraphDataset(torch_geometric.data.Dataset):\n",
    "    \"\"\"\n",
    "    This class encodes a collection of graphs, as well as a method to load such graphs from the disk.\n",
    "    It can be used in turn by the data loaders provided by pytorch geometric.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sample_files, edge_nfeats=2):\n",
    "        super().__init__(root=None, transform=None, pre_transform=None)\n",
    "        self.sample_files = sample_files\n",
    "        self.edge_nfeats = edge_nfeats\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.sample_files)\n",
    "\n",
    "    def get(self, index, nan_mask_val=0):\n",
    "        \"\"\"\n",
    "        This method loads a node bipartite graph observation as saved on the disk during data collection.\n",
    "        \"\"\"\n",
    "        sample = load_gzip(self.sample_files[index])\n",
    "        sample_observation, sample_action, sample_action_set, sample_scores = sample\n",
    "        \n",
    "        constraint_features = sample_observation.row_features\n",
    "        edge_indices = sample_observation.edge_features.indices.astype(np.int32)\n",
    "        edge_features = np.expand_dims(sample_observation.edge_features.values, axis=-1)\n",
    "        if self.edge_nfeats == 2:\n",
    "            edge_features_norm = edge_features / np.linalg.norm(edge_features) \n",
    "            edge_features = np.concatenate((edge_features, edge_features_norm), axis=-1)\n",
    "        variable_features = sample_observation.variable_features\n",
    "\n",
    "        constraint_features = np.nan_to_num(constraint_features, nan=nan_mask_val)\n",
    "        edge_features = np.nan_to_num(edge_features, nan=nan_mask_val)\n",
    "        variable_features = np.nan_to_num(variable_features, nan=nan_mask_val)\n",
    "\n",
    "        # We note on which variables we were allowed to branch, the scores as well as the choice\n",
    "        # taken by strong branching (relative to the candidates)\n",
    "        candidates = np.array(sample_action_set, dtype=np.int32)\n",
    "        candidate_scores = np.array([sample_scores[j] for j in candidates])\n",
    "        candidate_choice = np.where(candidates == sample_action)[0][0]\n",
    "\n",
    "        graph = BipartiteNodeData(\n",
    "            torch.FloatTensor(constraint_features),\n",
    "            torch.LongTensor(edge_indices),\n",
    "            torch.FloatTensor(edge_features),\n",
    "            torch.FloatTensor(variable_features),\n",
    "            torch.LongTensor(candidates),\n",
    "            len(candidates),\n",
    "            torch.LongTensor([candidate_choice]),\n",
    "            torch.FloatTensor(candidate_scores)\n",
    "        )\n",
    "\n",
    "        # We must tell pytorch geometric how many nodes there are, for indexing purposes\n",
    "        graph.num_nodes = constraint_features.shape[0] + variable_features.shape[0]\n",
    "\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52f70cf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gap_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m         obj = pickle.load(file)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m obj = \u001b[43mload_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata_0.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(obj)\n\u001b[32m     13\u001b[39m data = torch.load()  \u001b[38;5;66;03m# returns a Data (MyData) object\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mload_pickle\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_pickle\u001b[39m(path):\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m         obj = \u001b[43mpickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'gap_data'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def load_pickle(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        obj = pickle.load(file)\n",
    "    return obj\n",
    "\n",
    "obj = load_pickle(\"data_0.pkl\")\n",
    "\n",
    "print(obj)\n",
    "\n",
    "data = torch.load()  # returns a Data (MyData) object\n",
    "print(data.x_rows.shape, data.edge_index_rowcols.shape, data.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "339a8d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyData(x_rows=[70, 29], x_cols=[824, 17], edge_index_rowcols=[2, 1648], edge_vals_rowcols=[1648, 2])\n",
      "torch.Size([70, 29])\n",
      "torch.Size([824, 17])\n",
      "torch.Size([2, 1648])\n",
      "torch.Size([1648, 2])\n",
      "False None\n"
     ]
    }
   ],
   "source": [
    "# load_data.py\n",
    "import sys\n",
    "import types\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# 1) Create a fake module named gap_data with the bare minimum class\n",
    "gap_data = types.ModuleType(\"gap_data\")\n",
    "class MyData(Data):\n",
    "    \"\"\"Stub for the unpickled object.\"\"\"\n",
    "    pass\n",
    "gap_data.MyData = MyData\n",
    "# If there’s also MyDataWithLabels, stub it too:\n",
    "gap_data.MyDataWithLabels = type(\"MyDataWithLabels\", (Data,), {})\n",
    "\n",
    "# 2) Inject that module into sys.modules so torch.load can find it\n",
    "sys.modules[\"gap_data\"] = gap_data\n",
    "\n",
    "def load_pickle(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        obj = pickle.load(file)\n",
    "    return obj\n",
    "\n",
    "obj = load_pickle(\"data_0.pkl\")\n",
    "\n",
    "print(obj)\n",
    "\n",
    "\n",
    "print(obj.x_rows.shape)              # torch.Size([70, 29])\n",
    "print(obj.x_cols.shape)              # torch.Size([824, 17])\n",
    "print(obj.edge_index_rowcols.shape)  # torch.Size([2, 1648])\n",
    "print(obj.edge_vals_rowcols.shape)   # torch.Size([1648, 2])\n",
    "\n",
    "print(hasattr(obj, \"label\"), getattr(obj, \"label\", None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be837bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix: 70×824\n",
      "Top‑left 5×10 block of adj (raw coefficients):\n",
      "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "Feature vector length: 16038\n",
      "First 20 elements of feature vector:\n",
      "[0.         0.         1.         0.         0.         0.\n",
      " 1.         0.         0.         0.         0.14142136 0.\n",
      " 0.         0.         0.06067961 0.         0.         0.06067961\n",
      " 1.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# load_data.py\n",
    "import sys\n",
    "import types\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# 1) Stub the pickled module & classes\n",
    "gap_data = types.ModuleType(\"gap_data\")\n",
    "class MyData(Data): pass\n",
    "gap_data.MyData = MyData\n",
    "gap_data.MyDataWithLabels = type(\"MyDataWithLabels\", (Data,), {})\n",
    "sys.modules[\"gap_data\"] = gap_data\n",
    "\n",
    "# 2) Unpickle with pickle.load\n",
    "with open(\"data_0.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# 3) Convert tensors to numpy\n",
    "x_rows   = data.x_rows.numpy()               # [#rows, row_feat_dim]\n",
    "x_cols   = data.x_cols.numpy()               # [#cols, col_feat_dim]\n",
    "edge_idx = data.edge_index_rowcols.numpy()   # [2, E]\n",
    "edge_val = data.edge_vals_rowcols.numpy()    # [E, 2]  (take [:,0] for raw coeffs)\n",
    "\n",
    "num_rows, row_dim = x_rows.shape\n",
    "num_cols, col_dim = x_cols.shape\n",
    "\n",
    "# 4) Build dense adjacency matrix using the raw coefficient (col 0 of edge_val)\n",
    "adj = np.zeros((num_rows, num_cols), dtype=float)\n",
    "for r, c, v in zip(edge_idx[0], edge_idx[1], edge_val[:,0]):\n",
    "    adj[r, c] = v\n",
    "\n",
    "# 5) Print out adjacency snippet\n",
    "print(f\"Adjacency matrix: {num_rows}×{num_cols}\")\n",
    "print(\"Top‑left 5×10 block of adj (raw coefficients):\")\n",
    "print(adj[:5, :10])\n",
    "\n",
    "# 6) Flatten feature matrices into one long vector\n",
    "vec_rows = x_rows.reshape(-1)    # length = num_rows * row_dim\n",
    "vec_cols = x_cols.reshape(-1)    # length = num_cols * col_dim\n",
    "full_vec = np.concatenate([vec_rows, vec_cols])\n",
    "print(f\"\\nFeature vector length: {full_vec.size}\")\n",
    "print(\"First 20 elements of feature vector:\")\n",
    "print(full_vec[:20])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
